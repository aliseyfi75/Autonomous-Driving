{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import random\n",
    "from matplotlib import pyplot\n",
    "import math\n",
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "our task is to predict the future position of the ego vehicle 3 seconds into the future $y_i \\in \\mathbb{R}^{60}$  given $x_i$, one second of vehicle position data for the ego vehicle and (up to) the ten nearest agents to the ego at the point in time where prediction starts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in this part we are going to perform the following operations on the each dataset $X_i$:\n",
    "<ol>\n",
    "  <li>delete unwanted columns (time step, id, role, present)</li>\n",
    "  <li>convert non-numerical values to numerical</li>\n",
    "  <li>fill the empty columns so that each dataset has 10 elements (car, pedestrain/bicycle)</li>\n",
    "</ol>\n",
    "then we will perform the following operations on the each dataset $y_i$:\n",
    "<ol>\n",
    "  <li>not all the datasets contain 30 $(x, y)$ tuple, we are going to fill this broken datasets</li>\n",
    "  <li>delete unwanted columns (time step)</li>\n",
    "  <li>fill the empty columns so that each dataset has 10 elements (car, pedestrain/bicycle)</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data_X(data):\n",
    "    data = data.drop(columns = ['time step'])\n",
    "    \n",
    "    data = data.replace({\" car\": 1, \" pedestrian/bicycle\": 2})\n",
    "    data = data.replace({\" agent\": 1, \" others\": 2})\n",
    "    \n",
    "    #delete empty columns\n",
    "    data = data.replace({0: math.nan})\n",
    "    data = data.dropna(how='all', axis=1)\n",
    "    data = data.replace({math.nan: 0})\n",
    "\n",
    "    #we want our data to have 10 elements (car/pedestrain/bicycle) per dataset\n",
    "    m = int(data.columns[-1][-1])+1\n",
    "    n = 10\n",
    "    t = n-m\n",
    "    for i in range(m):\n",
    "        data = data.drop(columns = [' id' +str(i), ' present'+str(i)])\n",
    "\n",
    "    if m != n:        \n",
    "        s = np.random.choice(m, t)\n",
    "        for i in range(m,n):      \n",
    "            k = i-m\n",
    "            data[' role'+str(i)] = data[' role'+str(s[k])]\n",
    "            data[' type'+str(i)] = data[' type'+str(s[k])]\n",
    "            data[' x'+str(i)] = data[' x'+str(s[k])]\n",
    "            data[' y'+str(i)] = data[' y'+str(s[k])]\n",
    "    \n",
    "    \n",
    "    return data\n",
    "\n",
    "# clean_data_y needs to be implemented\n",
    "def clean_data_y(data):\n",
    "    size = 30    \n",
    "    if size != data.shape[0]:\n",
    "        diff=size-data.shape[0]    \n",
    "        x = data[' x'].values\n",
    "        y = data[' y'].values\n",
    "        t = data['time step'].values\n",
    "\n",
    "        model_x = AutoReg(x, 5)\n",
    "        model_y = AutoReg(y, 5)\n",
    "        model_t = AutoReg(t, 5)\n",
    "        predictions_x = model_x.fit().predict(start=len(x), end=len(x)+diff-1, dynamic=False)\n",
    "        predictions_y = model_y.fit().predict(start=len(y), end=len(y)+diff-1, dynamic=False)\n",
    "        predictions_t = model_t.fit().predict(start=len(t), end=len(t)+diff-1, dynamic=False)\n",
    "        d = np.concatenate((predictions_t.reshape(-1,1),predictions_x.reshape(-1,1),predictions_y.reshape(-1,1)),axis=1)\n",
    "        d = pd.DataFrame(d, columns=['time step',' x', ' y'])\n",
    "        data = data.append(d)\n",
    "    \n",
    "    return data.drop(columns = ['time step'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding New Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we are going to add some new features in this part namely speed direction, acceleration, turning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def continuous_angle(x):\n",
    "    \n",
    "    last = 0\n",
    "    out = []\n",
    "\n",
    "    for angle in x:\n",
    "        while angle < last-np.pi: angle += 2*np.pi\n",
    "        while angle > last+np.pi: angle -= 2*np.pi\n",
    "        last = angle\n",
    "        out.append(angle)\n",
    "\n",
    "    return np.array(out)\n",
    "\n",
    "#%%\n",
    "\n",
    "def speed_direction(data):\n",
    "\n",
    "    for i in range(10):\n",
    "        \n",
    "        speed = np.zeros(11)\n",
    "        sin_dir = np.zeros(11)\n",
    "        cos_dir = np.zeros(11)\n",
    "        \n",
    "        x = data[' x%d' % i]\n",
    "        y = data[' y%d' % i]\n",
    "        \n",
    "        speed[0] = np.sqrt((x[1]-x[0])**2+(y[1]-y[0])**2)\n",
    "        direction = np.arctan2(y[1]-y[0],x[1]-x[0])\n",
    "        sin_dir[0] = np.sin(direction)\n",
    "        cos_dir[0] = np.cos(direction)\n",
    "        \n",
    "        speed[10] = np.sqrt((x[10]-x[9])**2+(y[10]-y[9])**2)\n",
    "        direction = np.arctan2(y[10]-y[9],x[10]-x[9])\n",
    "        sin_dir[10] = np.sin(direction)\n",
    "        cos_dir[10] = np.cos(direction)\n",
    "        \n",
    "        for t in range(1,10):\n",
    "            \n",
    "            speed[t] = np.sqrt((x[t+1]-x[t-1])**2+(y[t+1]-y[t-1])**2)/2\n",
    "            direction = np.arctan2(y[t+1]-y[t-1],x[t+1]-x[t-1])\n",
    "            sin_dir[t] = np.sin(direction)\n",
    "            cos_dir[t] = np.cos(direction)\n",
    "            \n",
    "            \n",
    "        data[' speed%d' % i] = speed\n",
    "        data[' sin(dir)%d' % i] = sin_dir\n",
    "        data[' cos(dir)%d' % i] = cos_dir\n",
    "        \n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "def acceleration(data):\n",
    "    \n",
    "    for i in range(10):\n",
    "        \n",
    "        a = np.zeros(11)\n",
    "        \n",
    "        speed = data[' speed%d' % i]\n",
    "        \n",
    "        a[0] = speed[1]-speed[0]\n",
    "        a[10] = speed[10]-speed[9]\n",
    "        \n",
    "        for t in range(1,10):\n",
    "            a[t] = (speed[t+1]-speed[t-1])/2\n",
    "            \n",
    "            \n",
    "        data[' acceleration%d' % i] = a\n",
    "        \n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def turning(data):\n",
    "    \n",
    "    for i in range(10):\n",
    "        \n",
    "        turn = np.zeros(11)\n",
    "        \n",
    "        sin_dir = data[' sin(dir)%d' % i]\n",
    "        cos_dir = data[' cos(dir)%d' % i]\n",
    "        direction = np.arctan2(sin_dir, cos_dir)\n",
    "        direction = continuous_angle(direction)\n",
    "        \n",
    "        turn[0] = direction[1]-direction[0]\n",
    "        turn[10] = direction[10]-direction[9]\n",
    "        \n",
    "        for t in range(1,10):\n",
    "            turn[t] = (direction[t+1]-direction[t-1])/2\n",
    "            \n",
    "            \n",
    "        data[' turning%d' % i] = turn\n",
    "        \n",
    "    return data\n",
    "\n",
    "# add_features needs to be implemented\n",
    "def add_features(data):    \n",
    "    data = speed_direction(data)\n",
    "    data = acceleration(data)\n",
    "    data = turning(data)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading and Processing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in this part and next part we are going to iterate over all csv files and perform the following operation on each file:\n",
    "<ol>\n",
    "  <li>read the dataset</li>\n",
    "  <li>clean the dataset</li>\n",
    "  <li>add new features</li>\n",
    "  <li>reshape the dataset to a (1,x) shaped numpy array</li>\n",
    "  <li>merge all produced numpy arrays into a single matrix</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path):\n",
    "    data = pd.read_csv(path)\n",
    "    return data\n",
    "\n",
    "def get_path_X_train(i):\n",
    "    string = '../Data/train/X/X_'+str(i)+'.csv'\n",
    "    return string\n",
    "\n",
    "def get_path_y_train(i):\n",
    "    string = '../Data/train/y/y_'+str(i)+'.csv'\n",
    "    return string\n",
    "\n",
    "def get_path_X_val(i):\n",
    "    string = '../Data/val/X/X_'+str(i)+'.csv'\n",
    "    return string\n",
    "\n",
    "def get_path_y_val(i):\n",
    "    string = '../Data/val/y/y_'+str(i)+'.csv'\n",
    "    return string\n",
    "\n",
    "def get_path_X_test(i):\n",
    "    string = '../Data/test/X/X_'+str(i)+'.csv'\n",
    "    return string\n",
    "\n",
    "def convert(data):\n",
    "    return data.values.ravel()\n",
    "\n",
    "def get_data_X_train(i):    \n",
    "    return convert(add_features(clean_data_X(read_data(get_path_X_train(i)))))\n",
    "\n",
    "def get_data_y_train(i):\n",
    "    return convert(clean_data_y(read_data(get_path_y_train(i))))\n",
    "\n",
    "def get_data_X_val(i):\n",
    "    return convert(add_features(clean_data_X(read_data(get_path_X_val(i)))))\n",
    "\n",
    "def get_data_y_val(i):\n",
    "    return convert(clean_data_y(read_data(get_path_y_val(i))))\n",
    "\n",
    "def get_data_X_test(i):\n",
    "    return convert(add_features(clean_data_X(read_data(get_path_X_test(i)))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_train():\n",
    "    n = 2308\n",
    "    X_train = get_data_X_train(0).reshape(1,-1)\n",
    "    y_train = get_data_y_train(0).reshape(1,-1)\n",
    "    for i in range(1,n):\n",
    "        X_train = np.concatenate((X_train,get_data_X_train(i).reshape(1,-1)))\n",
    "        y_train = np.concatenate((y_train,get_data_y_train(i).reshape(1,-1)))\n",
    "    return X_train, y_train\n",
    "\n",
    "def get_data_val():\n",
    "    n = 524\n",
    "    X_val = get_data_X_val(0).reshape(1,-1)\n",
    "    y_val = get_data_y_val(0).reshape(1,-1)\n",
    "    for i in range(1,n):\n",
    "        X_val = np.concatenate((X_val,get_data_X_val(i).reshape(1,-1)))\n",
    "        y_val = np.concatenate((y_val,get_data_y_val(i).reshape(1,-1)))\n",
    "    return X_val, y_val\n",
    "\n",
    "def get_data_test():\n",
    "    n = 20\n",
    "    X_test = get_data_X_test(0).reshape(1,-1)\n",
    "    for i in range(1,n):\n",
    "        X_test = np.concatenate((X_test, get_data_X_test(i).reshape(1,-1)))\n",
    "    return X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = get_data_train()\n",
    "X_val, y_val = get_data_val()\n",
    "X_test = get_data_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2308, 990)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving The Processed Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(X_train).to_csv(\"../processed_data/X_train.csv\")\n",
    "pd.DataFrame(y_train).to_csv(\"../processed_data/y_train.csv\")\n",
    "pd.DataFrame(X_val).to_csv(\"../processed_data/X_val.csv\")\n",
    "pd.DataFrame(y_val).to_csv(\"../processed_data/y_val.csv\")\n",
    "pd.DataFrame(X_test).to_csv(\"../processed_data/X_test.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
