{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import math\n",
    "\n",
    "from numpy.linalg import norm\n",
    "from datetime import datetime\n",
    "from scipy.stats import skew  # for some statistics\n",
    "from scipy.special import boxcox1p\n",
    "from scipy.stats import boxcox_normmax\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import random\n",
    "from random import sample \n",
    "\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from neural_net import NeuralNet, NeuralNet_Chain, NeuralNet_Multiple, NeuralNet_Chain_skLearn\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "import add_features\n",
    "import DataClean\n",
    "from preprocess import preprocess\n",
    "\n",
    "\n",
    "import os\n",
    "import time\n",
    "import utils\n",
    "import pickle\n",
    "import gzip\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "our task is to predict the future position of the ego vehicle 3 seconds into the future $y_i \\in \\mathbb{R}^{60}$  given $x_i$, one second of vehicle position data for the ego vehicle and (up to) the ten nearest agents to the ego at the point in time where prediction starts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in this part we are going to perform the following operations on the each dataset $X_i$:\n",
    "<ol>\n",
    "  <li>delete unwanted columns (time step, id, role, present)</li>\n",
    "  <li>convert non-numerical values to numerical</li>\n",
    "  <li>fill the empty columns so that each dataset has 10 elements (car, pedestrain/bicycle)</li>\n",
    "</ol>\n",
    "then we will perform the following operations on the each dataset $y_i$:\n",
    "<ol>\n",
    "  <li>not all the datasets contain 30 $(x, y)$ tuple, we are going to fill this broken datasets</li>\n",
    "  <li>delete unwanted columns (time step)</li>\n",
    "  <li>fill the empty columns so that each dataset has 10 elements (car, pedestrain/bicycle)</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data_X(data):\n",
    "    data = data.drop(columns = ['time step'])\n",
    "    \n",
    "    data = data.replace({\" car\": 1, \" pedestrian/bicycle\": 2})\n",
    "    data = data.replace({\" agent\": 1, \" others\": 2})\n",
    "    \n",
    "    #delete empty columns\n",
    "    data = data.replace({0: math.nan})\n",
    "    data = data.dropna(how='all', axis=1)\n",
    "    data = data.replace({math.nan: 0})\n",
    "\n",
    "    #we want our data to have 10 elements (car/pedestrain/bicycle) per dataset\n",
    "    m = int(data.columns[-1][-1])+1\n",
    "    n = 10\n",
    "    t = n-m\n",
    "    for i in range(m):\n",
    "        data = data.drop(columns = [' id' +str(i), ' present'+str(i)])\n",
    "\n",
    "    if m != n:        \n",
    "        s = np.random.choice(m, t)\n",
    "        for i in range(m,n):      \n",
    "            k = i-m\n",
    "            data[' role'+str(i)] = data[' role'+str(s[k])]\n",
    "            data[' type'+str(i)] = data[' type'+str(s[k])]\n",
    "            data[' x'+str(i)] = data[' x'+str(s[k])]\n",
    "            data[' y'+str(i)] = data[' y'+str(s[k])]\n",
    "    \n",
    "    \n",
    "    return data\n",
    "\n",
    "def get_agent(data):\n",
    "    loc = int((np.where(np.array(data.iloc[0]) == ' agent')[0][0]-2)/6)\n",
    "    data_new = data[[' x'+str(loc),' y'+str(loc)]].rename(columns = {' x'+str(loc):'x',' y'+str(loc):'y'})\n",
    "    \n",
    "    return data_new\n",
    "\n",
    "def get_agent_x(data):\n",
    "    loc = int((np.where(np.array(data.iloc[0]) == ' agent')[0][0]-2)/6)\n",
    "    data_new = data[[' x'+str(loc)]].rename(columns = {' x'+str(loc):'x'})\n",
    "    \n",
    "    return data_new\n",
    "\n",
    "def get_agent_y(data):\n",
    "    loc = int((np.where(np.array(data.iloc[0]) == ' agent')[0][0]-2)/6)\n",
    "    data_new = data[[' y'+str(loc)]].rename(columns = {' y'+str(loc):'y'})\n",
    "    \n",
    "    return data_new\n",
    "\n",
    "# clean_data_y needs to be implemented\n",
    "def clean_data_y(data):\n",
    "    size = 30    \n",
    "    if size != data.shape[0]:\n",
    "        diff=size-data.shape[0]    \n",
    "        x = data[' x'].values\n",
    "        y = data[' y'].values\n",
    "        t = data['time step'].values\n",
    "\n",
    "        model_x = AutoReg(x, 5)\n",
    "        model_y = AutoReg(y, 5)\n",
    "        model_t = AutoReg(t, 5)\n",
    "        predictions_x = model_x.fit().predict(start=len(x), end=len(x)+diff-1, dynamic=False)\n",
    "        predictions_y = model_y.fit().predict(start=len(y), end=len(y)+diff-1, dynamic=False)\n",
    "        predictions_t = model_t.fit().predict(start=len(t), end=len(t)+diff-1, dynamic=False)\n",
    "        d = np.concatenate((predictions_t.reshape(-1,1),predictions_x.reshape(-1,1),predictions_y.reshape(-1,1)),axis=1)\n",
    "        d = pd.DataFrame(d, columns=['time step',' x', ' y'])\n",
    "        data = data.append(d)\n",
    "    \n",
    "    return data.drop(columns = ['time step'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding New Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we are going to add some new features in this part namely speed direction, acceleration, turning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def continuous_angle(x):\n",
    "    \n",
    "    last = 0\n",
    "    out = []\n",
    "\n",
    "    for angle in x:\n",
    "        while angle < last-np.pi: angle += 2*np.pi\n",
    "        while angle > last+np.pi: angle -= 2*np.pi\n",
    "        last = angle\n",
    "        out.append(angle)\n",
    "\n",
    "    return np.array(out)\n",
    "\n",
    "#%%\n",
    "\n",
    "def speed_direction(data):\n",
    "\n",
    "    for i in range(10):\n",
    "        \n",
    "        speed = np.zeros(11)\n",
    "        sin_dir = np.zeros(11)\n",
    "        cos_dir = np.zeros(11)\n",
    "        \n",
    "        x = data[' x%d' % i]\n",
    "        y = data[' y%d' % i]\n",
    "        \n",
    "        speed[0] = np.sqrt((x[1]-x[0])**2+(y[1]-y[0])**2)\n",
    "        direction = np.arctan2(y[1]-y[0],x[1]-x[0])\n",
    "        sin_dir[0] = np.sin(direction)\n",
    "        cos_dir[0] = np.cos(direction)\n",
    "        \n",
    "        speed[10] = np.sqrt((x[10]-x[9])**2+(y[10]-y[9])**2)\n",
    "        direction = np.arctan2(y[10]-y[9],x[10]-x[9])\n",
    "        sin_dir[10] = np.sin(direction)\n",
    "        cos_dir[10] = np.cos(direction)\n",
    "        \n",
    "        for t in range(1,10):\n",
    "            \n",
    "            speed[t] = np.sqrt((x[t+1]-x[t-1])**2+(y[t+1]-y[t-1])**2)/2\n",
    "            direction = np.arctan2(y[t+1]-y[t-1],x[t+1]-x[t-1])\n",
    "            sin_dir[t] = np.sin(direction)\n",
    "            cos_dir[t] = np.cos(direction)\n",
    "            \n",
    "            \n",
    "        data[' speed%d' % i] = speed\n",
    "        data[' sin(dir)%d' % i] = sin_dir\n",
    "        data[' cos(dir)%d' % i] = cos_dir\n",
    "        \n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "def acceleration(data):\n",
    "    \n",
    "    for i in range(10):\n",
    "        \n",
    "        a = np.zeros(11)\n",
    "        \n",
    "        speed = data[' speed%d' % i]\n",
    "        \n",
    "        a[0] = speed[1]-speed[0]\n",
    "        a[10] = speed[10]-speed[9]\n",
    "        \n",
    "        for t in range(1,10):\n",
    "            a[t] = (speed[t+1]-speed[t-1])/2\n",
    "            \n",
    "            \n",
    "        data[' acceleration%d' % i] = a\n",
    "        \n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def turning(data):\n",
    "    \n",
    "    for i in range(10):\n",
    "        \n",
    "        turn = np.zeros(11)\n",
    "        \n",
    "        sin_dir = data[' sin(dir)%d' % i]\n",
    "        cos_dir = data[' cos(dir)%d' % i]\n",
    "        direction = np.arctan2(sin_dir, cos_dir)\n",
    "        direction = continuous_angle(direction)\n",
    "        \n",
    "        turn[0] = direction[1]-direction[0]\n",
    "        turn[10] = direction[10]-direction[9]\n",
    "        \n",
    "        for t in range(1,10):\n",
    "            turn[t] = (direction[t+1]-direction[t-1])/2\n",
    "            \n",
    "            \n",
    "        data[' turning%d' % i] = turn\n",
    "        \n",
    "    return data\n",
    "\n",
    "# add_features needs to be implemented\n",
    "def add_features(data):    \n",
    "    data = speed_direction(data)\n",
    "    data = acceleration(data)\n",
    "    data = turning(data)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading and Processing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in this part and next part we are going to iterate over all csv files and perform the following operation on each file:\n",
    "<ol>\n",
    "  <li>read the dataset</li>\n",
    "  <li>clean the dataset</li>\n",
    "  <li>add new features</li>\n",
    "  <li>reshape the dataset to a (1,x) shaped numpy array</li>\n",
    "  <li>merge all produced numpy arrays into a single matrix</li>\n",
    "</ol>\n",
    "\n",
    "final update: instead of adding features and data cleaning part we just get the agent data using get_agent function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path):\n",
    "    data = pd.read_csv(path)\n",
    "    return data\n",
    "\n",
    "def get_path_X_train(i):\n",
    "    string = '../data2/train/X/X_'+str(i)+'.csv'\n",
    "    return string\n",
    "\n",
    "def get_path_y_train(i):\n",
    "    string = '../data2/train/y/y_'+str(i)+'.csv'\n",
    "    return string\n",
    "\n",
    "def get_path_X_val(i):\n",
    "    string = '../data2/val/X/X_'+str(i)+'.csv'\n",
    "    return string\n",
    "\n",
    "def get_path_y_val(i):\n",
    "    string = '../data2/val/y/y_'+str(i)+'.csv'\n",
    "    return string\n",
    "\n",
    "def get_path_X_test(i):\n",
    "    string = '../data2/test/X/X_'+str(i)+'.csv'\n",
    "    return string\n",
    "\n",
    "def convert(data):\n",
    "    return data.values.ravel()\n",
    "\n",
    "def get_data_X_train(i):    \n",
    "#     return convert(add_features(clean_data_X(read_data(get_path_X_train(i)))))\n",
    "#     return convert(clean_data_X(read_data(get_path_X_train(i))))\n",
    "    return convert(get_agent(read_data(get_path_X_train(i))))\n",
    "#     return convert(get_agent_x(read_data(get_path_X_train(i)))), convert(get_agent_y(read_data(get_path_X_train(i))))\n",
    "\n",
    "def get_data_y_train(i):\n",
    "    return convert(clean_data_y(read_data(get_path_y_train(i))))\n",
    "\n",
    "def get_data_X_val(i):\n",
    "#     return convert(add_features(clean_data_X(read_data(get_path_X_val(i)))))\n",
    "    return convert(get_agent(read_data(get_path_X_val(i))))\n",
    "#     return convert(get_agent_x(read_data(get_path_X_val(i)))), convert(get_agent_y(read_data(get_path_X_val(i))))\n",
    "def get_data_y_val(i):\n",
    "    return convert(clean_data_y(read_data(get_path_y_val(i))))\n",
    "\n",
    "def get_data_X_test(i):\n",
    "#     return convert(add_features(clean_data_X(read_data(get_path_X_test(i)))))\n",
    "    return convert(get_agent(read_data(get_path_X_test(i))))\n",
    "#     return convert(get_agent_x(read_data(get_path_X_test(i)))), convert(get_agent_y(read_data(get_path_X_test(i))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_train():\n",
    "    n = 2308\n",
    "    X_train = get_data_X_train(0).reshape(1,-1)\n",
    "    y_train = get_data_y_train(0).reshape(1,-1)\n",
    "    for i in range(1,n):\n",
    "        X_train = np.concatenate((X_train,get_data_X_train(i).reshape(1,-1)))\n",
    "        y_train = np.concatenate((y_train,get_data_y_train(i).reshape(1,-1)))\n",
    "    return X_train, y_train\n",
    "\n",
    "def get_data_val():\n",
    "    n = 524\n",
    "    X_val = get_data_X_val(0).reshape(1,-1)\n",
    "    y_val = get_data_y_val(0).reshape(1,-1)\n",
    "    for i in range(1,n):\n",
    "        X_val = np.concatenate((X_val,get_data_X_val(i).reshape(1,-1)))\n",
    "        y_val = np.concatenate((y_val,get_data_y_val(i).reshape(1,-1)))\n",
    "    return X_val, y_val\n",
    "\n",
    "def get_data_test():\n",
    "    n = 20\n",
    "    X_test = get_data_X_test(0).reshape(1,-1)\n",
    "    for i in range(1,n):\n",
    "        X_test = np.concatenate((X_test, get_data_X_test(i).reshape(1,-1)))\n",
    "    return X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_data_train():\n",
    "#     n = 2308\n",
    "#     X_train_x = get_data_X_train(0)[0].reshape(1,-1)\n",
    "#     X_train_y = get_data_X_train(0)[1].reshape(1,-1)\n",
    "#     y_train = get_data_y_train(0).reshape(1,-1)\n",
    "#     for i in range(1,n):\n",
    "#         X_train_x = np.concatenate((X_train_x,get_data_X_train(i)[0].reshape(1,-1)))\n",
    "#         X_train_y = np.concatenate((X_train_y,get_data_X_train(i)[1].reshape(1,-1)))\n",
    "#         y_train = np.concatenate((y_train,get_data_y_train(i).reshape(1,-1)))\n",
    "#     return X_train_x, X_train_y, y_train\n",
    "\n",
    "# def get_data_val():\n",
    "#     n = 524\n",
    "#     X_val_x = get_data_X_val(0)[0].reshape(1,-1)\n",
    "#     X_val_y = get_data_X_val(0)[1].reshape(1,-1)\n",
    "#     y_val = get_data_y_val(0).reshape(1,-1)\n",
    "#     for i in range(1,n):\n",
    "#         X_val_x = np.concatenate((X_val_x,get_data_X_val(i)[0].reshape(1,-1)))\n",
    "#         X_val_y = np.concatenate((X_val_y,get_data_X_val(i)[1].reshape(1,-1)))\n",
    "#         y_val = np.concatenate((y_val,get_data_y_val(i).reshape(1,-1)))\n",
    "#     return X_val_x, X_val_y, y_val\n",
    "\n",
    "# def get_data_test():\n",
    "#     n = 20\n",
    "#     X_test_x = get_data_X_test(0)[0].reshape(1,-1)\n",
    "#     X_test_y = get_data_X_test(0)[1].reshape(1,-1)\n",
    "#     for i in range(1,n):\n",
    "#         X_test_x = np.concatenate((X_test_x,get_data_X_test(i)[0].reshape(1,-1)))\n",
    "#         X_test_y = np.concatenate((X_test_y,get_data_X_test(i)[1].reshape(1,-1)))\n",
    "#     return X_test_x, X_test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, y_train = get_data_train()\n",
    "# X_val, y_val = get_data_val()\n",
    "# X_test = get_data_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X1_train, y1_train = get_data_train()\n",
    "# X1_val, y1_val = get_data_val()\n",
    "# X1_test = get_data_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_train, y2_train = get_data_train()\n",
    "X2_val, y2_val = get_data_val()\n",
    "X2_test = get_data_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X3_train_x, X3_train_y, y2_train = get_data_train()\n",
    "# X3_val_x, X3_val_y, y2_val = get_data_val()\n",
    "# X3_test_x, X3_test_y = get_data_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving The Processed Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(X_train).to_csv(\"../processed_data/X_train.csv\")\n",
    "# pd.DataFrame(y_train).to_csv(\"../processed_data/y_train.csv\")\n",
    "# pd.DataFrame(X_val).to_csv(\"../processed_data/X_val.csv\")\n",
    "# pd.DataFrame(y_val).to_csv(\"../processed_data/y_val.csv\")\n",
    "# pd.DataFrame(X_test).to_csv(\"../processed_data/X_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(X2_train).to_csv(\"../processed_data2/X_train.csv\")\n",
    "pd.DataFrame(y2_train).to_csv(\"../processed_data2/y_train.csv\")\n",
    "pd.DataFrame(X2_val).to_csv(\"../processed_data2/X_val.csv\")\n",
    "pd.DataFrame(y2_val).to_csv(\"../processed_data2/y_val.csv\")\n",
    "pd.DataFrame(X2_test).to_csv(\"../processed_data2/X_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chained_Ridge(X_train, y_train, X_test):\n",
    "    model_x = Ridge()\n",
    "    model_x.fit(X_train, y_train[:,0])\n",
    "    x_hat_train = model_x.predict(X_train)\n",
    "    x_hat_test = model_x.predict(X_test)\n",
    "\n",
    "    model_y = Ridge()\n",
    "    model_y.fit(X_train, y_train[:,1])\n",
    "    y_hat_train = model_y.predict(X_train)\n",
    "    y_hat_test = model_y.predict(X_test)\n",
    "\n",
    "    y_pred_train = np.concatenate((x_hat_train.reshape(-1,1), y_hat_train.reshape(-1,1)),axis=1)\n",
    "    y_pred_test = np.concatenate((x_hat_test.reshape(-1,1), y_hat_test.reshape(-1,1)),axis=1)\n",
    "\n",
    "    for i in range(2,60):\n",
    "        XN_train = np.concatenate((X_train,y_pred_train[:,i-2].reshape(-1,1)),axis =1)\n",
    "        XN_test = np.concatenate((X_test,y_pred_test[:,i-2].reshape(-1,1)), axis = 1)\n",
    "\n",
    "        model = Ridge()\n",
    "        model.fit(XN_train, y_train[:,i])\n",
    "        hat_train = model.predict(XN_train)\n",
    "        hat_test = model.predict(XN_test)\n",
    "\n",
    "        y_pred_train = np.concatenate((y_pred_train, hat_train.reshape(-1,1)),axis=1)\n",
    "        y_pred_test = np.concatenate((y_pred_test, hat_test.reshape(-1,1)),axis=1)\n",
    "        \n",
    "    return y_pred_train, y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3_train = np.concatenate((X2_train,X2_val),axis=0)\n",
    "y3_train = np.concatenate((y2_train,y2_val),axis=0)\n",
    "y_pred_train, y_pred_test = chained_KernelRidge(X3_train,y3_train,X2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'chained_NN_ONE_Layer_100N_s60_NotNormalized_NoRegularization.sav'\n",
    "\n",
    "# y_pred = model.predict(X2_test)\n",
    "\n",
    "xs = [str(i) + \"_x_\" + str(j) for i in range(20) for j in range(1, 31)]\n",
    "ys = [str(i) + \"_y_\" + str(j) for i in range(20) for j in range(1, 31)]\n",
    "\n",
    "ids = []\n",
    "for i in range(len(xs)):\n",
    "    ids.append(xs[i])\n",
    "    ids.append(ys[i])\n",
    "\n",
    "data = {'Id': ids,\n",
    "        'location': y_pred_test.reshape(-1,1).flatten()}\n",
    "\n",
    "df = pd.DataFrame(data, columns=['Id', 'location'])\n",
    "df.to_csv('ytest.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variation per principal component: [0.17160224 0.08648861 0.07963303]\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.manifold import TSNE\n",
    "# pca = PCA(n_components=3)\n",
    "# pca_result = pca.fit_transform(X_train)\n",
    "# df = pd.DataFrame((pca_result[:,0], pca_result[:,1], pca_result[:,2]))\n",
    "# print('Explained variation per principal component: {}'.format(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 121 nearest neighbors...\n",
      "[t-SNE] Indexed 2307 samples in 0.862s...\n",
      "[t-SNE] Computed neighbors for 2307 samples in 10.335s...\n",
      "[t-SNE] Computed conditional probabilities for sample 1000 / 2307\n",
      "[t-SNE] Computed conditional probabilities for sample 2000 / 2307\n",
      "[t-SNE] Computed conditional probabilities for sample 2307 / 2307\n",
      "[t-SNE] Mean sigma: 75.775670\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 75.650597\n",
      "[t-SNE] KL divergence after 300 iterations: 2.322378\n"
     ]
    }
   ],
   "source": [
    "# tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\n",
    "# tsne_results = tsne.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2307, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tsne_results\n",
    "# model = regre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "# sc_X = StandardScaler()\n",
    "# sc_y = StandardScaler()\n",
    "# SX_train = sc_X.fit_transform(X_train)\n",
    "# Sy_train = sc_y.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiOutputRegressor(estimator=KernelRidge(alpha=1.0))"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.kernel_ridge import KernelRidge\n",
    "# from sklearn.multioutput import MultiOutputRegressor\n",
    "# model = MultiOutputRegressor(KernelRidge(alpha=1.0))\n",
    "# model.fit(X2_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiOutputRegressor(estimator=SVR())"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.svm import SVR\n",
    "# model = MultiOutputRegressor(SVR(kernel='rbf'))\n",
    "# model.fit(X2_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiOutputRegressor(estimator=Ridge())"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.linear_model import Ridge\n",
    "# model = MultiOutputRegressor(Ridge())\n",
    "# model.fit(X2_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiOutputRegressor(estimator=Ridge())"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.linear_model import Ridge\n",
    "# model = MultiOutputRegressor(Ridge(alpha=1.0))\n",
    "# model.fit(X1_train, y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiOutputRegressor(estimator=Lasso())"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn import linear_model\n",
    "# model = MultiOutputRegressor(linear_model.Lasso())\n",
    "# model.fit(X2_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiOutputRegressor(estimator=MLPRegressor())"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.neural_network import MLPRegressor\n",
    "# model = MultiOutputRegressor(MLPRegressor())\n",
    "# model.fit(X2_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train error: 4.910352\n",
      "validation error: 4.768275\n"
     ]
    }
   ],
   "source": [
    "# y_pred = model.predict(X2_train)\n",
    "# train_error = np.mean(np.sqrt(np.sum((y_pred - y_train)**2,axis=1)))\n",
    "# print(\"train error: %f\" %train_error)\n",
    "\n",
    "# y_pred = model.predict(X2_val)\n",
    "# validation_error = np.mean(np.sqrt(np.sum((y_pred - y_val)**2,axis=1)))\n",
    "# print(\"validation error: %f\" %validation_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca = PCA(n_components=2)\n",
    "# pca_results_train = pca.fit_transform(X2_train)\n",
    "# pca_results_val = pca.fit_transform(X2_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiOutputRegressor(estimator=Ridge(alpha=1))"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = MultiOutputRegressor(Ridge(alpha=1))\n",
    "# model.fit(pca_results_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train error: 7.369057\n",
      "validation error: 28.320272\n"
     ]
    }
   ],
   "source": [
    "# y_pred = model.predict(pca_results_train)\n",
    "# train_error = np.mean(np.sqrt(np.sum((y_pred - y_train)**2,axis=1)))\n",
    "# print(\"train error: %f\" %train_error)\n",
    "\n",
    "# y_pred = model.predict(pca_results_val)\n",
    "# validation_error = np.mean(np.sqrt(np.sum((y_pred - y_val)**2,axis=1)))\n",
    "# print(\"validation error: %f\" %validation_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiOutputRegressor(estimator=SVR())"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.svm import SVR\n",
    "# model = MultiOutputRegressor(SVR(kernel='rbf'))\n",
    "# model.fit(pca_results_train, y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiOutputRegressor(estimator=MLPRegressor())"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "# model = MultiOutputRegressor(MLPRegressor())\n",
    "# model.fit(pca_results_train, y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiOutputRegressor(estimator=Lasso(alpha=0.001))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn import linear_model\n",
    "# model = MultiOutputRegressor(linear_model.Lasso(alpha=0.001))\n",
    "# model.fit(X1_train, y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = 0\n",
    "# y_xk_train = y1_train[:,k]\n",
    "# y_xk_val = y1_val[:,k]\n",
    "# XN_train = np.concatenate((X1_train,y1_train[:,k-2].reshape(-1,1)),axis =1)\n",
    "# XN_val = np.concatenate((X1_val,y1_val[:,k-2].reshape(-1,1)), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso()"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = linear_model.Lasso()\n",
    "# model.fit(XN_train, y_xk_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso()"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = linear_model.Lasso()\n",
    "# model.fit(X1_train, y_xk_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train error: 0.234284\n",
      "validation error: 0.241532\n"
     ]
    }
   ],
   "source": [
    "# y_xk_pred = model.predict(X1_train)\n",
    "# train_error = np.sqrt(np.mean((y_xk_pred - y1_train[:,k])**2))\n",
    "# print(\"train error: %f\" %train_error)\n",
    "\n",
    "# y_xk_pred = model.predict(X1_val)\n",
    "# validation_error = np.sqrt(np.mean((y_xk_pred - y1_val[:,k])**2))\n",
    "# print(\"validation error: %f\" %validation_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train error: 1.079208\n",
      "validation error: 0.906598\n"
     ]
    }
   ],
   "source": [
    "# y_xk_pred = model.predict(XN_train)\n",
    "# train_error = np.sqrt(np.mean((y_xk_pred - y1_train[:,k])**2))\n",
    "# print(\"train error: %f\" %train_error)\n",
    "\n",
    "# y_xk_pred = model.predict(XN_val)\n",
    "# validation_error = np.sqrt(np.mean((y_xk_pred - y1_val[:,k])**2))\n",
    "# print(\"validation error: %f\" %validation_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train error: 1.525991\n",
      "validation error: 1.244259\n"
     ]
    }
   ],
   "source": [
    "# y_x0_pred = model.predict(X1_train)\n",
    "# train_error = np.sqrt(np.mean((y_x0_pred - y1_train[:,k])**2))\n",
    "# print(\"train error: %f\" %train_error)\n",
    "\n",
    "# y_x0_pred = model.predict(X1_val)\n",
    "# validation_error = np.sqrt(np.mean((y_x0_pred - y1_val[:,k])**2))\n",
    "# print(\"validation error: %f\" %validation_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train error: 14.229291\n",
      "validation error: 14.956994\n"
     ]
    }
   ],
   "source": [
    "# y_pred = model.predict(pca_results_train)\n",
    "# train_error = np.mean(np.sqrt(np.sum((y_pred - y1_train)**2,axis=1)))\n",
    "# print(\"train error: %f\" %train_error)\n",
    "\n",
    "# y_pred = model.predict(pca_results_val)\n",
    "# validation_error = np.mean(np.sqrt(np.sum((y_pred - y1_val)**2,axis=1)))\n",
    "# print(\"validation error: %f\" %validation_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train error: 12.473731\n",
      "validation error: 14.619175\n"
     ]
    }
   ],
   "source": [
    "# y_pred = model.predict(X1_train)\n",
    "# train_error = np.mean(np.sqrt(np.sum((y_pred - y1_train)**2,axis=1)))\n",
    "# print(\"train error: %f\" %train_error)\n",
    "\n",
    "# y_pred = model.predict(X1_val)\n",
    "# validation_error = np.mean(np.sqrt(np.sum((y_pred - y1_val)**2,axis=1)))\n",
    "# print(\"validation error: %f\" %validation_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chained_Ridge(X_train, y_train, X_test):\n",
    "    model_x = Ridge()\n",
    "    model_x.fit(X_train, y_train[:,0])\n",
    "    x_hat_train = model_x.predict(X_train)\n",
    "    x_hat_test = model_x.predict(X_test)\n",
    "\n",
    "    model_y = Ridge()\n",
    "    model_y.fit(X_train, y_train[:,1])\n",
    "    y_hat_train = model_y.predict(X_train)\n",
    "    y_hat_test = model_y.predict(X_test)\n",
    "\n",
    "    y_pred_train = np.concatenate((x_hat_train.reshape(-1,1), y_hat_train.reshape(-1,1)),axis=1)\n",
    "    y_pred_test = np.concatenate((x_hat_test.reshape(-1,1), y_hat_test.reshape(-1,1)),axis=1)\n",
    "\n",
    "    for i in range(2,60):\n",
    "        XN_train = np.concatenate((X_train,y_pred_train[:,i-2].reshape(-1,1)),axis =1)\n",
    "        XN_test = np.concatenate((X_test,y_pred_test[:,i-2].reshape(-1,1)), axis = 1)\n",
    "\n",
    "        model = Ridge()\n",
    "        model.fit(XN_train, y_train[:,i])\n",
    "        hat_train = model.predict(XN_train)\n",
    "        hat_test = model.predict(XN_test)\n",
    "\n",
    "        y_pred_train = np.concatenate((y_pred_train, hat_train.reshape(-1,1)),axis=1)\n",
    "        y_pred_test = np.concatenate((y_pred_test, hat_test.reshape(-1,1)),axis=1)\n",
    "        \n",
    "    return y_pred_train, y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chained_Ridge_beta(X_train, y_train, X_test):\n",
    "    model_x = Ridge()\n",
    "    model_x.fit(X_train, y_train[:,0])\n",
    "    x_hat_train = model_x.predict(X_train)\n",
    "    x_hat_test = model_x.predict(X_test)\n",
    "\n",
    "    model_y = Ridge()\n",
    "    model_y.fit(X_train, y_train[:,1])\n",
    "    y_hat_train = model_y.predict(X_train)\n",
    "    y_hat_test = model_y.predict(X_test)\n",
    "\n",
    "    y_pred_train = np.concatenate((x_hat_train.reshape(-1,1), y_hat_train.reshape(-1,1)),axis=1)\n",
    "    y_pred_test = np.concatenate((x_hat_test.reshape(-1,1), y_hat_test.reshape(-1,1)),axis=1)\n",
    "    Xx_train = X_train\n",
    "    Xx_test = X_test\n",
    "    Xy_train = X_train\n",
    "    Xy_test = X_test\n",
    "    for i in range(1,30):\n",
    "        kx = 2*i\n",
    "        ky = 2*i+1\n",
    "        \n",
    "        Xx_train = np.concatenate((Xx_train,y_pred_train[:,kx-2].reshape(-1,1)),axis =1)\n",
    "        Xx_test = np.concatenate((Xx_test,y_pred_test[:,kx-2].reshape(-1,1)), axis = 1)\n",
    "        \n",
    "        Xy_train = np.concatenate((Xy_train,y_pred_train[:,ky-2].reshape(-1,1)),axis =1)\n",
    "        Xy_test = np.concatenate((Xy_test,y_pred_test[:,ky-2].reshape(-1,1)), axis = 1)\n",
    "        \n",
    "\n",
    "#         model = Ridge()\n",
    "#         model.fit(XN_train, y_train[:,i])\n",
    "#         hat_train = model.predict(XN_train)\n",
    "#         hat_test = model.predict(XN_test)\n",
    "\n",
    "#         y_pred_train = np.concatenate((y_pred_train, hat_train.reshape(-1,1)),axis=1)\n",
    "#         y_pred_test = np.concatenate((y_pred_test, hat_test.reshape(-1,1)),axis=1)\n",
    "        model_x = Ridge()\n",
    "        model_x.fit(Xx_train, y_train[:,0])\n",
    "        x_hat_train = model_x.predict(Xx_train)\n",
    "        x_hat_test = model_x.predict(Xx_test)\n",
    "\n",
    "        model_y = Ridge()\n",
    "        model_y.fit(Xy_train, y_train[:,1])\n",
    "        y_hat_train = model_y.predict(Xy_train)\n",
    "        y_hat_test = model_y.predict(Xy_test)\n",
    "\n",
    "        y_pred_train = np.concatenate((y_pred_train, x_hat_train.reshape(-1,1), y_hat_train.reshape(-1,1)),axis=1)\n",
    "        y_pred_test = np.concatenate((y_pred_test, x_hat_test.reshape(-1,1), y_hat_test.reshape(-1,1)),axis=1)\n",
    "        \n",
    "    return y_pred_train, y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chained_Ridge_x(X_train, y_train, X_test):\n",
    "    alpha = 1\n",
    "    model_x = Ridge(alpha)\n",
    "    model_x.fit(X_train, y_train[:,0])\n",
    "    x_hat_train = model_x.predict(X_train)\n",
    "    x_hat_test = model_x.predict(X_test)\n",
    "\n",
    "\n",
    "    y_pred_train_x = x_hat_train.reshape(-1,1)\n",
    "    y_pred_test_x = x_hat_test.reshape(-1,1)\n",
    "    \n",
    "    XN_train = X_train\n",
    "    XN_test = X_test\n",
    "    for i in range(1,30):        \n",
    "        XN_train = np.concatenate((XN_train,y_pred_train_x[:,i-1].reshape(-1,1)),axis =1)\n",
    "        XN_test = np.concatenate((XN_test,y_pred_test_x[:,i-1].reshape(-1,1)), axis = 1)\n",
    "\n",
    "        model = Ridge(alpha)\n",
    "        k = 6\n",
    "        model.fit(XN_train[:,-k:-1], y_train[:,2*i])\n",
    "        hat_train = model.predict(XN_train[:,-k:-1])\n",
    "        hat_test = model.predict(XN_test[:,-k:-1])\n",
    "\n",
    "        y_pred_train_x = np.concatenate((y_pred_train_x, hat_train.reshape(-1,1)),axis=1)\n",
    "        y_pred_test_x = np.concatenate((y_pred_test_x, hat_test.reshape(-1,1)),axis=1)\n",
    "        \n",
    "    return y_pred_train_x, y_pred_test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train error: 2.745274\n"
     ]
    }
   ],
   "source": [
    "X4_train_x = np.concatenate((X3_train_x,X3_val_x),axis=0)\n",
    "y4_train = np.concatenate((y2_train,y2_val),axis=0)\n",
    "y_pred_train_x, y_pred_test_x = chained_Ridge_x(X4_train_x,y4_train,X3_test_x)\n",
    "\n",
    "k=29\n",
    "train_error = np.sqrt(np.mean((y_pred_train_x[:,k] - y4_train[:,2*k])**2))\n",
    "print(\"train error: %f\" %train_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_x = Ridge()\n",
    "model_x.fit(X3_train_x, y2_train[:,0])\n",
    "x_hat_train = model_x.predict(X3_train_x)\n",
    "x_hat_test = model_x.predict(X3_test_x)\n",
    "y_pred_train_x = x_hat_train.reshape(-1,1)\n",
    "y_pred_test_x = x_hat_test.reshape(-1,1)\n",
    "XN_train = X3_train_x\n",
    "XN_test = X3_test_x\n",
    "for i in range(1,3):\n",
    "    XN_train = np.concatenate((XN_train,y_pred_train_x[:,i-1].reshape(-1,1)),axis=1)\n",
    "    XN_test = np.concatenate((XN_test,y_pred_test_x[:,i-1].reshape(-1,1)), axis = 1)\n",
    "    \n",
    "    model = Ridge()\n",
    "    model.fit(XN_train, y2_train[:,2*i])\n",
    "    hat_train = model.predict(XN_train)\n",
    "    hat_test = model.predict(XN_test)\n",
    "\n",
    "    y_pred_train_x = np.concatenate((y_pred_train_x, hat_train.reshape(-1,1)),axis=1)\n",
    "    y_pred_test_x = np.concatenate((y_pred_test_x, hat_test.reshape(-1,1)),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 3)"
      ]
     },
     "execution_count": 586,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiOutputRegressor(estimator=Ridge(alpha=1))"
      ]
     },
     "execution_count": 512,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultiOutputRegressor(Ridge(alpha=1))\n",
    "model.fit(X3_train_x, y2_train[:,2*np.arange(30)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train error: 3.339322\n",
      "validation error: 3.280116\n"
     ]
    }
   ],
   "source": [
    "k = 29\n",
    "y_x0_pred = model.predict(X3_train_x)\n",
    "train_error = np.sqrt(np.mean((y_x0_pred[:,k] - y2_train[:,2*k])**2))\n",
    "print(\"train error: %f\" %train_error)\n",
    "\n",
    "y_x0_pred = model.predict(X3_val_x)\n",
    "validation_error = np.sqrt(np.mean((y_x0_pred[:,k] - y2_val[:,2*k])**2))\n",
    "print(\"validation error: %f\" %validation_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiOutputRegressor(estimator=Ridge(alpha=1))"
      ]
     },
     "execution_count": 514,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultiOutputRegressor(Ridge(alpha=1))\n",
    "model.fit(X3_train_y, y2_train[:,2*np.arange(30)+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train error: 13.112452\n",
      "validation error: 13.148263\n"
     ]
    }
   ],
   "source": [
    "k = 29\n",
    "y_x0_pred = model.predict(X3_train_y)\n",
    "train_error = np.sqrt(np.mean((y_x0_pred[:,k] - y2_train[:,2*k+1])**2))\n",
    "print(\"train error: %f\" %train_error)\n",
    "\n",
    "y_x0_pred = model.predict(X3_val_y)\n",
    "validation_error = np.sqrt(np.mean((y_x0_pred[:,k] - y2_val[:,2*k+1])**2))\n",
    "print(\"validation error: %f\" %validation_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train error: 2.745007\n",
      "validation error: 2.735654\n"
     ]
    }
   ],
   "source": [
    "y_pred, y_val = chained_Ridge(X2_train, y2_train, X2_val)\n",
    "k = 58\n",
    "\n",
    "# y_x0_pred = model.predict(X3_train_y)\n",
    "train_error = np.sqrt(np.mean((y_pred[:,k] - y2_train[:,k])**2))\n",
    "print(\"train error: %f\" %train_error)\n",
    "\n",
    "# y_x0_pred = model.predict(X3_val_y)\n",
    "validation_error = np.sqrt(np.mean((y_val[:,k] - y2_val[:,k])**2))\n",
    "print(\"validation error: %f\" %validation_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train error: 3.231556\n",
      "validation error: 3.200428\n"
     ]
    }
   ],
   "source": [
    "model = MultiOutputRegressor(Ridge(alpha=1))\n",
    "model.fit(X2_train, y2_train)\n",
    "k = 58\n",
    "\n",
    "y_pred = model.predict(X2_train)\n",
    "train_error = np.sqrt(np.mean((y_pred[:,k] - y2_train[:,k])**2))\n",
    "print(\"train error: %f\" %train_error)\n",
    "\n",
    "y_val = model.predict(X2_val)\n",
    "validation_error = np.sqrt(np.mean((y_val[:,k] - y2_val[:,k])**2))\n",
    "print(\"validation error: %f\" %validation_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train error: 3.749028\n"
     ]
    }
   ],
   "source": [
    "X4_train_x = np.concatenate((X3_train_x,X3_val_x),axis=0)\n",
    "y4_train = np.concatenate((y2_train,y2_val),axis=0)\n",
    "y_pred_train_x, y_pred_test_x = chained_Ridge_x(X4_train_x,y4_train,X3_test_x)\n",
    "\n",
    "k=29\n",
    "train_error = np.sqrt(np.mean((y_pred_train_x[:,k] - y4_train[:,2*k])**2))\n",
    "print(\"train error: %f\" %train_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chained_KernelRidge(X_train, y_train, X_test):\n",
    "    model_x = SVR(kernel='rbf')\n",
    "    model_x.fit(X_train, y_train[:,0])\n",
    "    x_hat_train = model_x.predict(X_train)\n",
    "    x_hat_test = model_x.predict(X_test)\n",
    "\n",
    "    model_y = SVR(kernel='rbf')\n",
    "    model_y.fit(X_train, y_train[:,1])\n",
    "    y_hat_train = model_y.predict(X_train)\n",
    "    y_hat_test = model_y.predict(X_test)\n",
    "\n",
    "    y_pred_train = np.concatenate((x_hat_train.reshape(-1,1), y_hat_train.reshape(-1,1)),axis=1)\n",
    "    y_pred_test = np.concatenate((x_hat_test.reshape(-1,1), y_hat_test.reshape(-1,1)),axis=1)\n",
    "\n",
    "    for i in range(2,60):\n",
    "        XN_train = np.concatenate((X_train,y_pred_train[:,i-2].reshape(-1,1)),axis =1)\n",
    "        XN_test = np.concatenate((X_test,y_pred_test[:,i-2].reshape(-1,1)), axis = 1)\n",
    "\n",
    "        model = KernelRidge()\n",
    "        model.fit(XN_train, y_train[:,i])\n",
    "        hat_train = model.predict(XN_train)\n",
    "        hat_test = model.predict(XN_test)\n",
    "\n",
    "        y_pred_train = np.concatenate((y_pred_train, hat_train.reshape(-1,1)),axis=1)\n",
    "        y_pred_test = np.concatenate((y_pred_test, hat_test.reshape(-1,1)),axis=1)\n",
    "        \n",
    "    return y_pred_train, y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3_train = np.concatenate((X2_train,X2_val),axis=0)\n",
    "y3_train = np.concatenate((y2_train,y2_val),axis=0)\n",
    "y_pred_train, y_pred_test = chained_Ridge(X3_train,y3_train,X2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'chained_NN_ONE_Layer_100N_s60_NotNormalized_NoRegularization.sav'\n",
    "\n",
    "# y_pred = model.predict(X2_test)\n",
    "\n",
    "xs = [str(i) + \"_x_\" + str(j) for i in range(20) for j in range(1, 31)]\n",
    "ys = [str(i) + \"_y_\" + str(j) for i in range(20) for j in range(1, 31)]\n",
    "\n",
    "ids = []\n",
    "for i in range(len(xs)):\n",
    "    ids.append(xs[i])\n",
    "    ids.append(ys[i])\n",
    "\n",
    "data = {'Id': ids,\n",
    "        'location': y_pred_test.reshape(-1,1).flatten()}\n",
    "\n",
    "df = pd.DataFrame(data, columns=['Id', 'location'])\n",
    "df.to_csv('ytest.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train error: 3.595748\n"
     ]
    }
   ],
   "source": [
    "# y_pred = model.predict(X1_train)\n",
    "train_error = np.mean(np.sqrt(np.sum((y_pred_train - y3_train)**2,axis=1)))\n",
    "print(\"train error: %f\" %train_error)\n",
    "\n",
    "# y_pred = model.predict(X1_val)\n",
    "# validation_error = np.mean(np.sqrt(np.sum((y_pred_test - y2_val)**2,axis=1)))\n",
    "# print(\"validation error: %f\" %validation_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3_train = np.concatenate((X2_train,X2_val),axis=0)\n",
    "y3_train = np.concatenate((y2_train,y2_val),axis=0)\n",
    "y_pred_train, y_pred_test = chained_KernelRidge(X3_train,y3_train,X2_test)\n",
    "# y_pred_train, y_pred_test = chained_Ridge(X2_train,y2_train,X2_val)\n",
    "# test_error = []\n",
    "# for i in range(60):\n",
    "#     test_error.append(np.sqrt(np.mean((y_pred_test[:,i] - y_test[:,i])**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train error: 5.290451\n"
     ]
    }
   ],
   "source": [
    "train_error = np.mean(np.sqrt(np.sum((y_pred_train - y3_train)**2,axis=1)))\n",
    "print(\"train error: %f\" %train_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "model = MultiOutputRegressor(Ridge())\n",
    "model.fit(X3_train, y3_train)\n",
    "y_pred_train = model.predict(X3_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train error: 4.788315\n"
     ]
    }
   ],
   "source": [
    "# y_pred = model.predict(X1_train)\n",
    "y_pred_train = model.predict(X3_train)\n",
    "train_error = np.mean(np.sqrt(np.sum((y_pred_train - y3_train)**2,axis=1)))\n",
    "print(\"train error: %f\" %train_error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 - loss: 516879.737\n",
      "6 - loss: 498516.137\n",
      "7 - loss: 490142.202\n",
      "8 - loss: 483288.899\n",
      "9 - loss: 458613.773\n",
      "10 - loss: 417517.070\n",
      "11 - loss: 362342.323\n",
      "13 - loss: 354642.117\n",
      "14 - loss: 349707.557\n",
      "15 - loss: 346502.219\n",
      "16 - loss: 326734.796\n",
      "17 - loss: 305155.926\n",
      "18 - loss: 297783.957\n",
      "19 - loss: 292683.959\n",
      "20 - loss: 290747.590\n",
      "21 - loss: 289859.269\n",
      "22 - loss: 288725.403\n",
      "23 - loss: 283956.386\n",
      "24 - loss: 281022.941\n",
      "25 - loss: 280158.181\n",
      "26 - loss: 279676.348\n",
      "27 - loss: 279243.707\n",
      "28 - loss: 275236.325\n",
      "29 - loss: 268709.266\n",
      "30 - loss: 265096.714\n",
      "31 - loss: 263601.441\n",
      "32 - loss: 262702.112\n",
      "33 - loss: 262333.191\n",
      "34 - loss: 262016.791\n",
      "35 - loss: 260630.524\n",
      "36 - loss: 248801.162\n",
      "37 - loss: 215480.976\n",
      "39 - loss: 214782.180\n",
      "40 - loss: 214539.415\n",
      "41 - loss: 214321.381\n",
      "42 - loss: 213461.475\n",
      "43 - loss: 212480.861\n",
      "44 - loss: 210236.777\n",
      "45 - loss: 209514.996\n",
      "46 - loss: 209325.945\n",
      "47 - loss: 209150.153\n",
      "48 - loss: 208245.109\n",
      "49 - loss: 138126.349\n",
      "51 - loss: 128129.598\n",
      "52 - loss: 128001.933\n",
      "53 - loss: 127954.222\n",
      "54 - loss: 127889.476\n",
      "55 - loss: 127076.490\n",
      "56 - loss: 126274.858\n",
      "57 - loss: 126181.114\n",
      "58 - loss: 126130.393\n",
      "59 - loss: 126089.607\n",
      "60 - loss: 124935.953\n",
      "61 - loss: 122253.219\n",
      "62 - loss: 122198.375\n",
      "63 - loss: 122085.158\n",
      "64 - loss: 122050.108\n",
      "65 - loss: 121745.240\n",
      "66 - loss: 121278.238\n",
      "67 - loss: 120723.116\n",
      "68 - loss: 120672.259\n",
      "69 - loss: 120640.170\n",
      "70 - loss: 120607.557\n",
      "71 - loss: 98733.586\n",
      "73 - loss: 95102.717\n",
      "74 - loss: 95092.425\n",
      "75 - loss: 95082.724\n",
      "76 - loss: 94817.103\n",
      "77 - loss: 94531.813\n",
      "78 - loss: 94456.210\n",
      "79 - loss: 94439.881\n",
      "80 - loss: 94431.090\n",
      "81 - loss: 94408.543\n",
      "82 - loss: 88072.638\n",
      "84 - loss: 88052.723\n",
      "85 - loss: 88045.163\n",
      "86 - loss: 88038.517\n",
      "87 - loss: 87374.127\n",
      "88 - loss: 86764.032\n",
      "89 - loss: 86730.646\n",
      "90 - loss: 86721.143\n",
      "91 - loss: 86715.162\n",
      "92 - loss: 86435.782\n",
      "93 - loss: 86163.474\n",
      "94 - loss: 86139.265\n",
      "95 - loss: 86130.320\n",
      "96 - loss: 86124.643\n",
      "97 - loss: 85922.010\n",
      "98 - loss: 76714.449\n",
      "100 - loss: 76706.368\n",
      "101 - loss: 76702.660\n",
      "102 - loss: 76699.549\n",
      "103 - loss: 74238.927\n",
      "105 - loss: 74232.037\n",
      "106 - loss: 74225.757\n",
      "107 - loss: 74223.125\n",
      "108 - loss: 74107.904\n",
      "109 - loss: 73808.092\n",
      "110 - loss: 73330.314\n",
      "112 - loss: 73325.065\n",
      "113 - loss: 73322.135\n",
      "114 - loss: 73319.795\n",
      "115 - loss: 72572.670\n",
      "116 - loss: 72062.878\n",
      "117 - loss: 71895.065\n",
      "118 - loss: 71885.584\n",
      "119 - loss: 71883.289\n",
      "120 - loss: 71771.816\n",
      "121 - loss: 71539.613\n",
      "123 - loss: 71533.621\n",
      "124 - loss: 71531.407\n",
      "125 - loss: 71529.447\n",
      "126 - loss: 70805.539\n",
      "127 - loss: 70313.920\n",
      "128 - loss: 70037.056\n",
      "129 - loss: 70022.321\n",
      "130 - loss: 70020.204\n",
      "131 - loss: 69961.326\n",
      "132 - loss: 69809.178\n",
      "134 - loss: 69800.738\n",
      "135 - loss: 69799.042\n",
      "136 - loss: 69797.440\n",
      "137 - loss: 67202.699\n",
      "139 - loss: 67200.434\n",
      "140 - loss: 67198.749\n",
      "141 - loss: 67197.619\n",
      "142 - loss: 66996.733\n",
      "143 - loss: 66797.525\n",
      "144 - loss: 66794.388\n",
      "145 - loss: 66791.700\n",
      "146 - loss: 66790.693\n",
      "147 - loss: 66576.173\n",
      "148 - loss: 65723.737\n",
      "150 - loss: 65699.528\n",
      "151 - loss: 65698.679\n",
      "152 - loss: 65697.820\n",
      "153 - loss: 65575.296\n",
      "154 - loss: 65457.874\n",
      "155 - loss: 65456.444\n",
      "156 - loss: 65454.776\n",
      "157 - loss: 65454.010\n",
      "158 - loss: 65053.473\n",
      "160 - loss: 65013.953\n",
      "161 - loss: 64974.434\n",
      "162 - loss: 64973.725\n",
      "163 - loss: 64973.009\n",
      "164 - loss: 64874.657\n",
      "165 - loss: 64778.911\n",
      "166 - loss: 64773.549\n",
      "167 - loss: 64772.845\n",
      "168 - loss: 64772.151\n",
      "170 - loss: 63836.138\n",
      "172 - loss: 63827.776\n",
      "173 - loss: 63827.224\n",
      "174 - loss: 63826.677\n",
      "175 - loss: 63672.912\n",
      "176 - loss: 63522.462\n",
      "178 - loss: 63521.431\n",
      "179 - loss: 63520.756\n",
      "180 - loss: 63520.257\n",
      "181 - loss: 63426.497\n",
      "182 - loss: 63331.843\n",
      "183 - loss: 63331.150\n",
      "184 - loss: 63329.603\n",
      "185 - loss: 63329.138\n",
      "186 - loss: 63206.045\n",
      "187 - loss: 62767.936\n",
      "189 - loss: 62766.764\n",
      "190 - loss: 62766.271\n",
      "191 - loss: 62765.844\n",
      "192 - loss: 62712.355\n",
      "193 - loss: 62660.422\n",
      "194 - loss: 62659.960\n",
      "195 - loss: 62659.546\n",
      "196 - loss: 62659.140\n",
      "198 - loss: 62176.768\n",
      "200 - loss: 62175.514\n",
      "201 - loss: 62175.013\n",
      "202 - loss: 62174.575\n",
      "203 - loss: 62139.683\n",
      "204 - loss: 62103.786\n",
      "205 - loss: 62102.226\n",
      "206 - loss: 62101.791\n",
      "207 - loss: 62101.350\n",
      "208 - loss: 61998.309\n",
      "210 - loss: 61995.042\n",
      "211 - loss: 61991.790\n",
      "212 - loss: 61991.363\n",
      "213 - loss: 61957.724\n",
      "214 - loss: 61902.655\n",
      "215 - loss: 61900.031\n",
      "216 - loss: 61899.606\n",
      "217 - loss: 61899.181\n",
      "218 - loss: 61864.815\n",
      "219 - loss: 61838.239\n",
      "220 - loss: 61837.337\n",
      "221 - loss: 61836.912\n",
      "223 - loss: 61334.991\n",
      "225 - loss: 61327.166\n",
      "226 - loss: 61326.704\n",
      "227 - loss: 61326.238\n",
      "228 - loss: 61263.115\n",
      "229 - loss: 61207.826\n",
      "230 - loss: 61202.716\n",
      "231 - loss: 61202.277\n",
      "232 - loss: 61201.871\n",
      "233 - loss: 61121.261\n",
      "234 - loss: 61083.213\n",
      "235 - loss: 61059.162\n",
      "236 - loss: 61058.764\n",
      "237 - loss: 61058.326\n",
      "238 - loss: 60804.467\n",
      "240 - loss: 60803.655\n",
      "241 - loss: 60802.968\n",
      "242 - loss: 60802.582\n",
      "243 - loss: 60757.252\n",
      "244 - loss: 60712.536\n",
      "245 - loss: 60709.950\n",
      "246 - loss: 60709.568\n",
      "247 - loss: 60709.188\n",
      "248 - loss: 60205.207\n",
      "250 - loss: 60202.844\n",
      "251 - loss: 60202.471\n",
      "252 - loss: 60202.113\n",
      "253 - loss: 60168.820\n",
      "254 - loss: 60135.991\n",
      "255 - loss: 60135.286\n",
      "256 - loss: 60134.882\n",
      "257 - loss: 60134.538\n",
      "258 - loss: 59292.471\n",
      "260 - loss: 59264.823\n",
      "261 - loss: 59264.532\n",
      "262 - loss: 59264.086\n",
      "263 - loss: 59214.007\n",
      "264 - loss: 59175.188\n",
      "265 - loss: 59167.161\n",
      "266 - loss: 59166.853\n",
      "267 - loss: 59166.582\n",
      "268 - loss: 59144.166\n",
      "269 - loss: 59119.869\n",
      "270 - loss: 59116.123\n",
      "271 - loss: 59114.641\n",
      "272 - loss: 59114.381\n",
      "273 - loss: 59113.728\n",
      "274 - loss: 58427.503\n",
      "276 - loss: 58426.001\n",
      "277 - loss: 58425.782\n",
      "278 - loss: 58425.567\n",
      "279 - loss: 58408.858\n",
      "280 - loss: 58392.983\n",
      "281 - loss: 58392.532\n",
      "282 - loss: 58392.275\n",
      "283 - loss: 58392.079\n",
      "284 - loss: 58275.297\n",
      "286 - loss: 58274.836\n",
      "287 - loss: 58274.411\n",
      "288 - loss: 58274.232\n",
      "289 - loss: 58265.483\n",
      "290 - loss: 58252.263\n",
      "291 - loss: 58211.581\n",
      "292 - loss: 58209.309\n",
      "293 - loss: 58209.115\n",
      "294 - loss: 58208.943\n",
      "295 - loss: 58160.676\n",
      "296 - loss: 58082.634\n",
      "297 - loss: 58075.840\n",
      "298 - loss: 58075.113\n",
      "299 - loss: 58074.915\n",
      "300 - loss: 58065.260\n",
      "301 - loss: 58055.919\n",
      "302 - loss: 58055.650\n",
      "303 - loss: 58055.481\n",
      "304 - loss: 58055.318\n",
      "305 - loss: 57603.878\n",
      "307 - loss: 57599.028\n",
      "308 - loss: 57598.855\n",
      "309 - loss: 57598.624\n",
      "310 - loss: 57590.928\n",
      "311 - loss: 57584.187\n",
      "312 - loss: 57583.921\n",
      "313 - loss: 57583.750\n",
      "314 - loss: 57583.618\n",
      "315 - loss: 57552.540\n",
      "316 - loss: 57522.985\n",
      "317 - loss: 57521.248\n",
      "318 - loss: 57521.103\n",
      "319 - loss: 57520.978\n",
      "320 - loss: 57509.525\n",
      "321 - loss: 57496.739\n",
      "322 - loss: 57496.088\n",
      "323 - loss: 57495.744\n",
      "324 - loss: 57495.621\n",
      "325 - loss: 57492.461\n",
      "326 - loss: 57479.941\n",
      "327 - loss: 57451.972\n",
      "328 - loss: 57450.477\n",
      "329 - loss: 57450.339\n",
      "330 - loss: 57450.218\n",
      "331 - loss: 57443.611\n",
      "332 - loss: 57436.883\n",
      "333 - loss: 57434.473\n",
      "334 - loss: 57434.227\n",
      "335 - loss: 57434.107\n",
      "336 - loss: 57433.942\n",
      "337 - loss: 56885.487\n",
      "339 - loss: 56870.104\n",
      "340 - loss: 56869.954\n",
      "341 - loss: 56866.049\n",
      "342 - loss: 56862.832\n",
      "343 - loss: 56861.568\n",
      "344 - loss: 56860.999\n",
      "345 - loss: 56860.915\n",
      "346 - loss: 56860.812\n",
      "347 - loss: 56845.250\n",
      "348 - loss: 56830.930\n",
      "349 - loss: 56830.104\n",
      "350 - loss: 56830.021\n",
      "351 - loss: 56829.941\n",
      "352 - loss: 56821.474\n",
      "353 - loss: 56812.670\n",
      "354 - loss: 56812.452\n",
      "355 - loss: 56812.299\n",
      "356 - loss: 56812.220\n",
      "357 - loss: 56809.513\n",
      "358 - loss: 56806.272\n",
      "359 - loss: 56800.901\n",
      "360 - loss: 56800.731\n",
      "361 - loss: 56800.652\n",
      "362 - loss: 56800.573\n",
      "363 - loss: 56504.630\n",
      "365 - loss: 56502.013\n",
      "366 - loss: 56501.929\n",
      "367 - loss: 56501.833\n",
      "368 - loss: 56497.391\n",
      "369 - loss: 56493.146\n",
      "370 - loss: 56491.086\n",
      "371 - loss: 56490.302\n",
      "372 - loss: 56490.229\n",
      "373 - loss: 56490.156\n",
      "374 - loss: 56483.740\n",
      "375 - loss: 56477.299\n",
      "376 - loss: 56477.016\n",
      "377 - loss: 56476.824\n",
      "378 - loss: 56476.752\n",
      "379 - loss: 56475.986\n",
      "380 - loss: 56473.762\n",
      "381 - loss: 56471.411\n",
      "382 - loss: 56471.027\n",
      "383 - loss: 56470.954\n",
      "384 - loss: 56470.883\n",
      "385 - loss: 56469.878\n",
      "386 - loss: 56412.471\n",
      "388 - loss: 56412.129\n",
      "389 - loss: 56411.793\n",
      "390 - loss: 56411.722\n",
      "391 - loss: 56410.220\n",
      "392 - loss: 56407.304\n",
      "393 - loss: 56404.450\n",
      "394 - loss: 56404.369\n",
      "395 - loss: 56404.299\n",
      "396 - loss: 56404.228\n",
      "397 - loss: 56364.707\n",
      "398 - loss: 56364.262\n",
      "399 - loss: 56362.799\n",
      "400 - loss: 56362.729\n",
      "401 - loss: 56361.110\n",
      "402 - loss: 56343.383\n",
      "403 - loss: 56335.966\n",
      "404 - loss: 56334.946\n",
      "405 - loss: 56334.876\n",
      "406 - loss: 56334.806\n",
      "407 - loss: 56326.732\n",
      "408 - loss: 56319.610\n",
      "409 - loss: 56319.498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "410 - loss: 56319.427\n",
      "411 - loss: 56319.357\n",
      "412 - loss: 56317.361\n",
      "413 - loss: 56315.358\n",
      "414 - loss: 56314.562\n",
      "415 - loss: 56314.491\n",
      "416 - loss: 56314.421\n",
      "417 - loss: 56314.306\n",
      "418 - loss: 56159.177\n",
      "420 - loss: 56158.630\n",
      "421 - loss: 56158.558\n",
      "422 - loss: 56158.488\n",
      "423 - loss: 56155.925\n",
      "424 - loss: 56153.333\n",
      "425 - loss: 56150.585\n",
      "426 - loss: 56150.484\n",
      "427 - loss: 56150.415\n",
      "428 - loss: 56150.346\n",
      "429 - loss: 56145.110\n",
      "430 - loss: 56139.770\n",
      "431 - loss: 56139.319\n",
      "432 - loss: 56139.237\n",
      "433 - loss: 56139.169\n",
      "434 - loss: 56138.898\n",
      "435 - loss: 56137.125\n",
      "436 - loss: 56135.324\n",
      "437 - loss: 56131.552\n",
      "438 - loss: 56131.476\n",
      "439 - loss: 56131.407\n",
      "440 - loss: 56131.339\n",
      "441 - loss: 56111.283\n",
      "442 - loss: 56106.629\n",
      "443 - loss: 56106.463\n",
      "444 - loss: 56106.394\n",
      "445 - loss: 56106.333\n",
      "447 - loss: 55554.507\n",
      "449 - loss: 55543.148\n",
      "450 - loss: 55542.962\n",
      "451 - loss: 55542.260\n",
      "452 - loss: 55540.007\n",
      "453 - loss: 55538.301\n",
      "454 - loss: 55537.668\n",
      "455 - loss: 55537.435\n",
      "456 - loss: 55537.353\n",
      "457 - loss: 55537.216\n",
      "458 - loss: 55528.193\n",
      "459 - loss: 55519.757\n",
      "460 - loss: 55519.500\n",
      "461 - loss: 55519.421\n",
      "462 - loss: 55519.346\n",
      "463 - loss: 55509.336\n",
      "464 - loss: 55499.327\n",
      "465 - loss: 55499.194\n",
      "466 - loss: 55499.116\n",
      "467 - loss: 55499.042\n",
      "468 - loss: 55497.642\n",
      "469 - loss: 55496.243\n",
      "470 - loss: 55494.050\n",
      "471 - loss: 55493.972\n",
      "472 - loss: 55493.898\n",
      "473 - loss: 55493.832\n",
      "475 - loss: 55137.446\n",
      "476 - loss: 55137.360\n",
      "477 - loss: 55135.231\n",
      "478 - loss: 55135.099\n",
      "479 - loss: 55133.086\n",
      "480 - loss: 55131.244\n",
      "481 - loss: 55126.107\n",
      "483 - loss: 55125.927\n",
      "484 - loss: 55125.813\n",
      "485 - loss: 55125.728\n",
      "486 - loss: 55120.484\n",
      "487 - loss: 55114.975\n",
      "488 - loss: 55113.363\n",
      "489 - loss: 55113.149\n",
      "490 - loss: 55113.022\n",
      "491 - loss: 55112.938\n",
      "492 - loss: 55111.094\n",
      "493 - loss: 55109.114\n",
      "494 - loss: 55104.470\n",
      "495 - loss: 55103.259\n",
      "496 - loss: 55103.145\n",
      "497 - loss: 55103.061\n",
      "498 - loss: 55102.942\n",
      "499 - loss: 55078.854\n",
      "500 - loss: 55056.332\n",
      "501 - loss: 55055.614\n",
      "502 - loss: 55055.528\n",
      "503 - loss: 55055.413\n",
      "504 - loss: 55054.106\n",
      "505 - loss: 55052.817\n",
      "507 - loss: 54330.011\n",
      "508 - loss: 54223.075\n",
      "509 - loss: 54213.732\n",
      "510 - loss: 54213.142\n",
      "511 - loss: 54209.165\n",
      "512 - loss: 54207.242\n",
      "513 - loss: 54204.897\n",
      "514 - loss: 54204.657\n",
      "515 - loss: 54204.505\n",
      "516 - loss: 54204.357\n",
      "517 - loss: 54183.903\n",
      "518 - loss: 54169.045\n",
      "519 - loss: 54166.937\n",
      "520 - loss: 54165.525\n",
      "521 - loss: 54165.367\n",
      "522 - loss: 54160.815\n",
      "523 - loss: 54156.745\n",
      "524 - loss: 54156.059\n",
      "525 - loss: 54155.713\n",
      "526 - loss: 54155.599\n",
      "527 - loss: 54155.475\n",
      "528 - loss: 54153.453\n",
      "529 - loss: 54151.303\n",
      "530 - loss: 54147.082\n",
      "531 - loss: 54144.604\n",
      "532 - loss: 54144.337\n",
      "533 - loss: 54144.226\n",
      "534 - loss: 54144.109\n",
      "535 - loss: 54140.970\n",
      "536 - loss: 54137.496\n",
      "537 - loss: 54135.177\n",
      "538 - loss: 54134.293\n",
      "539 - loss: 54134.155\n",
      "540 - loss: 54134.046\n",
      "541 - loss: 54133.910\n",
      "542 - loss: 54125.721\n",
      "543 - loss: 54116.213\n",
      "544 - loss: 54114.625\n",
      "545 - loss: 54113.894\n",
      "546 - loss: 54113.579\n",
      "547 - loss: 54113.472\n",
      "548 - loss: 54113.329\n",
      "549 - loss: 54110.081\n",
      "550 - loss: 54106.332\n",
      "551 - loss: 54104.170\n",
      "552 - loss: 54103.022\n",
      "553 - loss: 54102.900\n",
      "554 - loss: 54102.794\n",
      "555 - loss: 54102.683\n",
      "556 - loss: 54067.942\n",
      "557 - loss: 54033.807\n",
      "558 - loss: 54033.749\n",
      "559 - loss: 54032.126\n",
      "560 - loss: 54031.915\n",
      "561 - loss: 54030.510\n",
      "562 - loss: 54029.265\n",
      "563 - loss: 54028.057\n",
      "564 - loss: 54027.956\n",
      "565 - loss: 54027.850\n",
      "566 - loss: 54027.773\n",
      "568 - loss: 53171.976\n",
      "570 - loss: 53162.442\n",
      "571 - loss: 53161.498\n",
      "572 - loss: 53160.164\n",
      "573 - loss: 53151.403\n",
      "574 - loss: 53145.101\n",
      "575 - loss: 53140.268\n",
      "576 - loss: 53139.331\n",
      "577 - loss: 53138.717\n",
      "578 - loss: 53138.484\n",
      "579 - loss: 53134.061\n",
      "580 - loss: 53130.033\n",
      "581 - loss: 53127.919\n",
      "582 - loss: 53127.658\n",
      "583 - loss: 53127.289\n",
      "584 - loss: 53127.140\n",
      "585 - loss: 53125.310\n",
      "586 - loss: 53123.125\n",
      "587 - loss: 53118.324\n",
      "588 - loss: 53116.923\n",
      "589 - loss: 53116.308\n",
      "590 - loss: 53116.174\n",
      "591 - loss: 53116.025\n",
      "592 - loss: 53112.690\n",
      "593 - loss: 53108.881\n",
      "594 - loss: 53107.067\n",
      "595 - loss: 53106.834\n",
      "596 - loss: 53106.694\n",
      "597 - loss: 53106.563\n",
      "598 - loss: 53104.545\n",
      "599 - loss: 53102.296\n",
      "600 - loss: 53099.094\n",
      "601 - loss: 53098.363\n",
      "602 - loss: 53098.211\n",
      "603 - loss: 53098.082\n",
      "604 - loss: 53097.785\n",
      "605 - loss: 53088.621\n",
      "606 - loss: 53074.828\n",
      "607 - loss: 53074.458\n",
      "608 - loss: 53073.655\n",
      "609 - loss: 53073.520\n",
      "610 - loss: 53073.391\n",
      "611 - loss: 53072.212\n",
      "612 - loss: 53071.033\n",
      "613 - loss: 53037.802\n",
      "614 - loss: 53036.170\n",
      "615 - loss: 53004.255\n",
      "616 - loss: 53004.131\n",
      "617 - loss: 53003.988\n",
      "618 - loss: 53002.880\n",
      "619 - loss: 53001.774\n",
      "620 - loss: 52994.753\n",
      "621 - loss: 52994.517\n",
      "622 - loss: 52994.395\n",
      "623 - loss: 52994.274\n",
      "624 - loss: 52910.687\n",
      "626 - loss: 52908.625\n",
      "627 - loss: 52906.573\n",
      "628 - loss: 52906.453\n",
      "629 - loss: 52906.105\n",
      "630 - loss: 52905.035\n",
      "631 - loss: 52903.961\n",
      "632 - loss: 52898.526\n",
      "633 - loss: 52898.290\n",
      "634 - loss: 52898.170\n",
      "635 - loss: 52898.050\n",
      "636 - loss: 52877.312\n",
      "637 - loss: 52861.768\n",
      "638 - loss: 52861.590\n",
      "639 - loss: 52861.470\n",
      "640 - loss: 52860.422\n",
      "641 - loss: 52859.370\n",
      "643 - loss: 52509.658\n",
      "645 - loss: 52509.202\n",
      "646 - loss: 52509.057\n",
      "647 - loss: 52508.924\n",
      "648 - loss: 52507.885\n",
      "649 - loss: 52506.868\n",
      "650 - loss: 52504.303\n",
      "651 - loss: 52503.821\n",
      "652 - loss: 52503.698\n",
      "653 - loss: 52503.578\n",
      "654 - loss: 52495.452\n",
      "655 - loss: 52465.271\n",
      "656 - loss: 52463.699\n",
      "657 - loss: 52463.431\n",
      "658 - loss: 52463.311\n",
      "659 - loss: 52463.021\n",
      "660 - loss: 52461.812\n",
      "661 - loss: 52460.383\n",
      "662 - loss: 52452.388\n",
      "663 - loss: 52443.061\n",
      "664 - loss: 52442.915\n",
      "665 - loss: 52442.795\n",
      "666 - loss: 52442.663\n",
      "667 - loss: 52441.668\n",
      "668 - loss: 52440.669\n",
      "669 - loss: 52411.164\n",
      "670 - loss: 52320.131\n",
      "671 - loss: 52316.274\n",
      "672 - loss: 52316.006\n",
      "673 - loss: 52315.076\n",
      "674 - loss: 52314.956\n",
      "675 - loss: 52314.831\n",
      "676 - loss: 52312.562\n",
      "677 - loss: 52310.266\n",
      "678 - loss: 52309.220\n",
      "679 - loss: 52308.388\n",
      "680 - loss: 52308.265\n",
      "681 - loss: 52308.146\n",
      "682 - loss: 52307.922\n",
      "683 - loss: 52083.037\n",
      "685 - loss: 52082.499\n",
      "686 - loss: 52081.972\n",
      "687 - loss: 52081.854\n",
      "688 - loss: 52081.607\n",
      "689 - loss: 52076.970\n",
      "690 - loss: 52071.822\n",
      "691 - loss: 52069.062\n",
      "692 - loss: 52068.881\n",
      "693 - loss: 52068.762\n",
      "694 - loss: 52068.643\n",
      "695 - loss: 52067.698\n",
      "696 - loss: 52066.725\n",
      "697 - loss: 52044.451\n",
      "698 - loss: 52033.371\n",
      "699 - loss: 52032.574\n",
      "700 - loss: 52032.456\n",
      "701 - loss: 52032.315\n",
      "702 - loss: 52030.623\n",
      "703 - loss: 52028.812\n",
      "704 - loss: 52027.323\n",
      "705 - loss: 52026.142\n",
      "706 - loss: 52025.994\n",
      "707 - loss: 52025.876\n",
      "708 - loss: 52025.754\n",
      "709 - loss: 52005.144\n",
      "710 - loss: 51975.871\n",
      "711 - loss: 51975.559\n",
      "712 - loss: 51975.113\n",
      "713 - loss: 51974.985\n",
      "714 - loss: 51974.821\n",
      "715 - loss: 51973.921\n",
      "716 - loss: 51973.039\n",
      "717 - loss: 51972.071\n",
      "718 - loss: 51971.936\n",
      "719 - loss: 51971.818\n",
      "720 - loss: 51971.688\n",
      "721 - loss: 51938.239\n",
      "722 - loss: 51905.030\n",
      "723 - loss: 51904.434\n",
      "724 - loss: 51904.181\n",
      "725 - loss: 51904.046\n",
      "726 - loss: 51901.892\n",
      "727 - loss: 51899.844\n",
      "728 - loss: 51898.938\n",
      "729 - loss: 51898.568\n",
      "730 - loss: 51898.447\n",
      "731 - loss: 51898.331\n",
      "732 - loss: 51891.921\n",
      "733 - loss: 51882.155\n",
      "734 - loss: 51881.106\n",
      "735 - loss: 51880.826\n",
      "736 - loss: 51880.703\n",
      "737 - loss: 51880.586\n",
      "738 - loss: 51879.630\n",
      "739 - loss: 51878.576\n",
      "740 - loss: 51864.546\n",
      "741 - loss: 51820.205\n",
      "742 - loss: 51819.113\n",
      "743 - loss: 51818.986\n",
      "744 - loss: 51818.857\n",
      "745 - loss: 51817.963\n",
      "746 - loss: 51817.077\n",
      "747 - loss: 51814.980\n",
      "748 - loss: 51812.538\n",
      "749 - loss: 51812.316\n",
      "750 - loss: 51812.199\n",
      "751 - loss: 51812.083\n",
      "752 - loss: 51771.428\n",
      "753 - loss: 51700.338\n",
      "754 - loss: 51691.121\n",
      "755 - loss: 51690.230\n",
      "756 - loss: 51689.816\n",
      "757 - loss: 51688.224\n",
      "758 - loss: 51687.404\n",
      "759 - loss: 51686.961\n",
      "760 - loss: 51686.840\n",
      "761 - loss: 51686.725\n",
      "762 - loss: 51686.391\n",
      "763 - loss: 51676.993\n",
      "764 - loss: 51664.443\n",
      "765 - loss: 51662.610\n",
      "766 - loss: 51662.416\n",
      "767 - loss: 51662.301\n",
      "768 - loss: 51662.187\n",
      "769 - loss: 51656.596\n",
      "770 - loss: 51650.069\n",
      "771 - loss: 51648.846\n",
      "772 - loss: 51648.614\n",
      "773 - loss: 51648.496\n",
      "774 - loss: 51648.382\n",
      "775 - loss: 51647.522\n",
      "776 - loss: 51646.583\n",
      "777 - loss: 51634.572\n",
      "778 - loss: 51614.166\n",
      "779 - loss: 51613.615\n",
      "780 - loss: 51613.499\n",
      "781 - loss: 51613.380\n",
      "782 - loss: 51612.204\n",
      "783 - loss: 51610.977\n",
      "784 - loss: 51609.743\n",
      "785 - loss: 51608.514\n",
      "786 - loss: 51608.336\n",
      "787 - loss: 51608.222\n",
      "788 - loss: 51608.107\n",
      "789 - loss: 51599.745\n",
      "790 - loss: 51587.806\n",
      "791 - loss: 51586.965\n",
      "792 - loss: 51586.769\n",
      "793 - loss: 51586.648\n",
      "794 - loss: 51586.535\n",
      "795 - loss: 51585.019\n",
      "796 - loss: 51583.335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "797 - loss: 51581.614\n",
      "798 - loss: 51580.242\n",
      "799 - loss: 51580.069\n",
      "800 - loss: 51579.956\n",
      "801 - loss: 51579.841\n",
      "802 - loss: 51576.816\n",
      "803 - loss: 51572.840\n",
      "804 - loss: 51571.647\n",
      "805 - loss: 51571.012\n",
      "806 - loss: 51570.892\n",
      "807 - loss: 51570.779\n",
      "808 - loss: 51570.651\n",
      "809 - loss: 51565.120\n",
      "810 - loss: 51557.672\n",
      "811 - loss: 51556.730\n",
      "812 - loss: 51556.443\n",
      "813 - loss: 51556.324\n",
      "814 - loss: 51556.211\n",
      "815 - loss: 51555.242\n",
      "816 - loss: 51554.104\n",
      "817 - loss: 51546.569\n",
      "818 - loss: 51523.287\n",
      "819 - loss: 51523.023\n",
      "820 - loss: 51522.895\n",
      "821 - loss: 51522.776\n",
      "822 - loss: 51521.987\n",
      "823 - loss: 51521.203\n",
      "824 - loss: 51507.165\n",
      "825 - loss: 51506.655\n",
      "826 - loss: 51506.521\n",
      "827 - loss: 51506.409\n",
      "828 - loss: 51472.029\n",
      "829 - loss: 51356.967\n",
      "830 - loss: 51308.263\n",
      "831 - loss: 51308.116\n",
      "832 - loss: 51307.854\n",
      "833 - loss: 51307.039\n",
      "834 - loss: 51306.264\n",
      "835 - loss: 51304.884\n",
      "836 - loss: 51304.725\n",
      "837 - loss: 51304.615\n",
      "838 - loss: 51304.506\n",
      "839 - loss: 51300.576\n",
      "840 - loss: 51296.354\n",
      "841 - loss: 51293.485\n",
      "842 - loss: 51293.352\n",
      "843 - loss: 51293.243\n",
      "844 - loss: 51293.133\n",
      "845 - loss: 51292.086\n",
      "846 - loss: 51290.932\n",
      "847 - loss: 51288.318\n",
      "848 - loss: 51283.336\n",
      "849 - loss: 51283.163\n",
      "850 - loss: 51283.053\n",
      "851 - loss: 51282.944\n",
      "852 - loss: 51282.171\n",
      "853 - loss: 51281.362\n",
      "854 - loss: 51260.906\n",
      "855 - loss: 51135.088\n",
      "856 - loss: 51109.781\n",
      "857 - loss: 51109.442\n",
      "858 - loss: 51109.311\n",
      "859 - loss: 51108.534\n",
      "860 - loss: 51107.815\n",
      "861 - loss: 51106.193\n",
      "862 - loss: 51104.906\n",
      "863 - loss: 51104.792\n",
      "864 - loss: 51104.688\n",
      "865 - loss: 51104.514\n",
      "866 - loss: 51007.565\n",
      "868 - loss: 51006.558\n",
      "869 - loss: 51005.561\n",
      "870 - loss: 51005.459\n",
      "871 - loss: 51005.263\n",
      "872 - loss: 51004.205\n",
      "873 - loss: 51002.783\n",
      "874 - loss: 51000.490\n",
      "875 - loss: 50999.019\n",
      "876 - loss: 50998.871\n",
      "877 - loss: 50998.769\n",
      "878 - loss: 50998.666\n",
      "879 - loss: 50997.820\n",
      "880 - loss: 50996.886\n",
      "881 - loss: 50993.264\n",
      "882 - loss: 50981.341\n",
      "883 - loss: 50981.140\n",
      "884 - loss: 50981.022\n",
      "885 - loss: 50980.920\n",
      "886 - loss: 50980.329\n",
      "887 - loss: 50979.673\n",
      "888 - loss: 50977.908\n",
      "889 - loss: 50975.340\n",
      "890 - loss: 50975.226\n",
      "891 - loss: 50975.125\n",
      "892 - loss: 50975.022\n",
      "893 - loss: 50669.455\n",
      "895 - loss: 50669.164\n",
      "896 - loss: 50669.032\n",
      "897 - loss: 50668.922\n",
      "898 - loss: 50668.335\n",
      "899 - loss: 50667.761\n",
      "900 - loss: 50666.810\n",
      "901 - loss: 50666.684\n",
      "902 - loss: 50666.591\n",
      "903 - loss: 50666.496\n",
      "904 - loss: 50654.011\n",
      "905 - loss: 50640.482\n",
      "906 - loss: 50639.052\n",
      "907 - loss: 50638.813\n",
      "908 - loss: 50638.684\n",
      "909 - loss: 50638.592\n",
      "910 - loss: 50637.796\n",
      "911 - loss: 50636.936\n",
      "912 - loss: 50635.450\n",
      "913 - loss: 50632.022\n",
      "914 - loss: 50630.361\n",
      "915 - loss: 50629.918\n",
      "916 - loss: 50629.810\n",
      "917 - loss: 50629.718\n",
      "918 - loss: 50629.625\n",
      "919 - loss: 50628.516\n",
      "920 - loss: 50627.163\n",
      "921 - loss: 50625.802\n",
      "922 - loss: 50624.858\n",
      "923 - loss: 50624.199\n",
      "924 - loss: 50624.076\n",
      "925 - loss: 50623.985\n",
      "926 - loss: 50623.890\n",
      "927 - loss: 50601.814\n",
      "928 - loss: 50568.933\n",
      "929 - loss: 50566.477\n",
      "931 - loss: 50566.099\n",
      "932 - loss: 50566.002\n",
      "933 - loss: 50565.912\n",
      "934 - loss: 50565.338\n",
      "935 - loss: 50564.749\n",
      "936 - loss: 50552.622\n",
      "937 - loss: 50386.911\n",
      "939 - loss: 50386.081\n",
      "941 - loss: 50385.806\n",
      "942 - loss: 50385.698\n",
      "943 - loss: 50385.603\n",
      "944 - loss: 50385.074\n",
      "945 - loss: 50384.548\n",
      "946 - loss: 50379.952\n",
      "947 - loss: 50378.728\n",
      "948 - loss: 50378.306\n",
      "949 - loss: 50378.221\n",
      "950 - loss: 50377.855\n",
      "951 - loss: 50372.064\n",
      "952 - loss: 50345.673\n",
      "953 - loss: 50344.550\n",
      "954 - loss: 50344.190\n",
      "955 - loss: 50343.962\n",
      "956 - loss: 50343.873\n",
      "957 - loss: 50343.789\n",
      "958 - loss: 50343.289\n",
      "959 - loss: 50342.786\n",
      "960 - loss: 50311.597\n",
      "961 - loss: 49971.285\n",
      "962 - loss: 49822.133\n",
      "963 - loss: 49814.966\n",
      "964 - loss: 49814.437\n",
      "965 - loss: 49811.226\n",
      "966 - loss: 49809.849\n",
      "967 - loss: 49809.016\n",
      "968 - loss: 49808.456\n",
      "969 - loss: 49808.287\n",
      "970 - loss: 49808.190\n",
      "971 - loss: 49808.104\n",
      "972 - loss: 49805.555\n",
      "973 - loss: 49801.739\n",
      "974 - loss: 49801.019\n",
      "975 - loss: 49800.617\n",
      "976 - loss: 49800.481\n",
      "977 - loss: 49800.388\n",
      "978 - loss: 49800.320\n",
      "979 - loss: 49798.709\n",
      "980 - loss: 49796.644\n",
      "981 - loss: 49796.099\n",
      "982 - loss: 49795.730\n",
      "983 - loss: 49795.615\n",
      "984 - loss: 49795.547\n",
      "985 - loss: 49795.480\n",
      "986 - loss: 49775.360\n",
      "987 - loss: 49727.019\n",
      "988 - loss: 49725.022\n",
      "989 - loss: 49724.368\n",
      "990 - loss: 49724.225\n",
      "991 - loss: 49723.005\n",
      "992 - loss: 49722.188\n",
      "993 - loss: 49721.780\n",
      "994 - loss: 49721.417\n",
      "995 - loss: 49721.253\n",
      "996 - loss: 49721.185\n",
      "997 - loss: 49721.118\n",
      "998 - loss: 49720.529\n",
      "999 - loss: 49716.027\n",
      "1000 - loss: 49712.305\n",
      "Reached maximum number of function evaluations 1000\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNet_Chain(hidden_layer_sizes=[[100]],classification=False, lammy=np.array([0.001]),s=60, max_iter=np.array([1000]), verbose=True)\n",
    "model.fit(X2_train,y2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'chained_NN_ONE_Layer_100N_s60_NotNormalized_NoRegularization.sav'\n",
    "\n",
    "# y_pred = model.predict(X2_test)\n",
    "\n",
    "xs = [str(i) + \"_x_\" + str(j) for i in range(20) for j in range(1, 31)]\n",
    "ys = [str(i) + \"_y_\" + str(j) for i in range(20) for j in range(1, 31)]\n",
    "\n",
    "ids = []\n",
    "for i in range(len(xs)):\n",
    "    ids.append(xs[i])\n",
    "    ids.append(ys[i])\n",
    "\n",
    "data = {'Id': ids,\n",
    "        'location': y_pred_test.reshape(-1,1).flatten()}\n",
    "\n",
    "df = pd.DataFrame(data, columns=['Id', 'location'])\n",
    "df.to_csv('ytest.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_x_1</td>\n",
       "      <td>1.020550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_y_1</td>\n",
       "      <td>-0.002434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_x_2</td>\n",
       "      <td>2.023388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_y_2</td>\n",
       "      <td>-0.008287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_x_3</td>\n",
       "      <td>3.042025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>19_y_28</td>\n",
       "      <td>-0.141414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>19_x_29</td>\n",
       "      <td>11.480890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>19_y_29</td>\n",
       "      <td>-0.149091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>19_x_30</td>\n",
       "      <td>13.159775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199</th>\n",
       "      <td>19_y_30</td>\n",
       "      <td>-0.239018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1200 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Id   location\n",
       "0       0_x_1   1.020550\n",
       "1       0_y_1  -0.002434\n",
       "2       0_x_2   2.023388\n",
       "3       0_y_2  -0.008287\n",
       "4       0_x_3   3.042025\n",
       "...       ...        ...\n",
       "1195  19_y_28  -0.141414\n",
       "1196  19_x_29  11.480890\n",
       "1197  19_y_29  -0.149091\n",
       "1198  19_x_30  13.159775\n",
       "1199  19_y_30  -0.239018\n",
       "\n",
       "[1200 rows x 2 columns]"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('../data/X_train.csv')\n",
    "X_train = np.array(X_train.iloc[:,1:])\n",
    "y_train = pd.read_csv('../data/y_train.csv')\n",
    "y_train = np.array(y_train.iloc[:,1:])\n",
    "X_val = pd.read_csv('../data/X_val.csv')\n",
    "X_val = np.array(X_val.iloc[:,1:])\n",
    "y_val = pd.read_csv('../data/y_val.csv')\n",
    "y_val = np.array(y_val.iloc[:,1:])\n",
    "X_test = pd.read_csv('../data/X_test.csv')\n",
    "X_test = np.array(X_test.iloc[:,1:])\n",
    "\n",
    "print(\"X_train  \\n n = %d, d = %d\" %(X_train.shape[0],X_train.shape[1]))\n",
    "print(\"y_train  \\n n = %d, d = %d\" %(y_train.shape[0],y_train.shape[1]))\n",
    "print(\"X_val  \\n n = %d, d = %d\" %(X_val.shape[0],X_val.shape[1]))\n",
    "print(\"y_val  \\n n = %d, d = %d\" %(y_val.shape[0],y_val.shape[1]))\n",
    "print(\"X_test  \\n n = %d, d = %d\" %(X_test.shape[0],X_test.shape[1]))\n",
    "\n",
    "# X_train_normalized, mu_x, sigma_x = utils.standardize_cols(X_train)\n",
    "# y_train_normalized, mu_y, sigma_y = utils.standardize_cols(y_train)\n",
    "# X_val_normalized, _, _ = utils.standardize_cols(X_val,mu_x,sigma_x)\n",
    "# y_val_normalized, _, _ = utils.standardize_cols(y_val,mu_y,sigma_y)\n",
    "# X_test_normalized, _, _ = utils.standardize_cols(X_test,mu_x,sigma_x)\n",
    "# model = NeuralNet_Chain_skLearn(hidden_layer_sizes=[(200,100)],classification=False, lammy=np.array([1]),s=60, max_iter=np.array([1000]), verbose=True, activation='relu')\n",
    "model = NeuralNet_Chain(hidden_layer_sizes=[[100]],classification=False, lammy=np.array([0.001]),s=60, max_iter=np.array([1000]), verbose=True)\n",
    "model.fit(np.concatenate((X_train,X_val),axis=0),np.concatenate((y_train,y_val),axis=0))\n",
    "\n",
    "# model = MLPRegressor(alpha=1.0,verbose='True')\n",
    "# model.fit(X_train, y_train)\n",
    "\n",
    "# y_pred = model.predict(X_train_normalized)\n",
    "# train_error = np.mean(np.sqrt(np.sum((y_pred - y_train)**2,axis=1)))\n",
    "# print(\"train error: %f\" %train_error)\n",
    "#\n",
    "# y_pred = model.predict(X_val_normalized)\n",
    "# validation_error = np.mean(np.sqrt(np.sum((y_pred - y_val)**2,axis=1)))\n",
    "# print(\"validation error: %f\" %validation_error)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
